Полное руководство по классическому ML'ю

---
## Общие вопросы

### Вопрос: Что такое взрыв и затухание градиента?
**Ответ:**
**Затухание градиента (vanishing gradients)** — ситуация, когда величины градиентов становятся очень маленькими (стремятся к нулю), из‑за чего шаги обновления параметров почти исчезают и обучение практически “останавливается”. Это часто проявляется в глубоких моделях (особенно рекуррентных/очень глубоких сетях) из-за многократного перемножения производных меньше 1 (например, в цепном правиле). В результате ранние слои/параметры получают почти нулевой сигнал ошибки, учатся крайне медленно, модель долго не улучшает качество.

**Взрыв градиента (exploding gradients)** — противоположная проблема: градиенты становятся слишком большими, обновления параметров “перепрыгивают” оптимум, значения весов могут быстро уходить в очень большие числа, функция потерь начинает колебаться или расходиться (NaN/Inf). Причина — многократное перемножение производных больше 1, неудачный масштаб входов/инициализации, слишком большой learning rate и т.п.

**Как распознать на практике:**
- Затухание: loss почти не уменьшается, нормы градиента около 0, обучение “стоит”, особенно в ранних слоях.
- Взрыв: loss скачет/растёт, появляются NaN/Inf, нормы градиента резко растут.

**Типовые меры борьбы (универсальные):**
- Нормализация/стандартизация входов (снижает проблемы масштаба).
- Правильная инициализация весов (Xavier/He для нейросетей).
- Подбор learning rate, использование адаптивных оптимизаторов (Adam/Adagrad) — осторожно, не всегда лечит причину.
- Gradient clipping (ограничение нормы градиента) — особенно эффективно против взрыва.
- Архитектурные приёмы в deep learning: residual connections, нормализации (BatchNorm/LayerNorm), gated-архитектуры (LSTM/GRU) для RNN.
- Регуляризация и контроль масштаба весов (частично помогает стабилизировать обучение).

---

## Линейная регрессия

### 1. Общие вопросы по линейной регрессии

#### Вопрос: Что такое линейная регрессия и как она работает?
**Ответ:**
Линейная регрессия — алгоритм регрессии, который моделирует зависимость целевой переменной $y$ от признаков $x$ как линейную функцию параметров. В простейшем виде (один объект) предсказание записывается как:
$$\hat{y} = w^\top x + b$$
где $w$ — вектор коэффициентов (весов), $b$ — свободный член (bias).

В матричном виде для датасета из $n$ объектов и $p$ признаков:
- $X \in \\mathbb{R}^{n \\times p}$ — матрица признаков,
- $w \in \\mathbb{R}^p$,
- $b \in \\mathbb{R}$,
- $y \in \\mathbb{R}^n$.
Тогда:
$$\hat{y} = Xw + b\bf{1}$$
Интуитивно каждый коэффициент $w_j$ показывает, насколько меняется предсказание при увеличении признака $x_j$ на 1 (при прочих равных), а $b$ задаёт базовый уровень.

Обучение линейной регрессии — это подбор $w$ и $b$, чтобы предсказания $\hat{y}$ были максимально близки к истинным $y$ по выбранной функции потерь (обычно MSE).

---

### 2. Преимущества линейной регрессии

#### Вопрос: Какие преимущества у линейной регрессии?
**Ответ:**
- Простота и интерпретируемость: коэффициенты легко трактовать, можно объяснять влияние признаков на результат.
- Быстрое обучение: при умеренном числе признаков оптимизация быстрая; для OLS есть аналитическое решение (если матрицы обратимы).
- Хорошая базовая модель: часто служит сильным baseline и помогает быстро обнаружить проблемы данных (выбросы, масштабирование, мультиколлинеарность).
- Возможность расширения: линейную модель можно сделать “нелинейной по признакам”, добавив полиномиальные/взаимодействующие признаки, при этом параметры остаются линейными.

---

### 3. Функция потерь в линейной регрессии

#### Вопрос: Какая функция потерь используется в линейной регрессии?
**Ответ:**
Чаще всего используют среднеквадратичную ошибку (MSE):
$$MSE(w,b) = \frac{1}{n} \sum_{i=1}^{n} \left( \hat{y}_i - y_i \right)^2
$$
Она измеряет средний квадрат отклонения предсказаний от истинных значений. Иногда используют $\frac{1}{2n}$ вместо $\frac{1}{n}$ для удобства производных.

#### Вопрос: Почему в линейной регрессии используется квадратичная функция потерь?
**Ответ:**
- Выпуклость: для линейной модели MSE даёт выпуклую задачу, а значит (при корректных условиях) есть один глобальный минимум.
- Удобные производные: градиенты простые и стабильные, аналитическое решение (OLS) выводится напрямую.
- Статистическая интерпретация: при предположении нормального шума в данных минимизация MSE эквивалентна максимизации правдоподобия (MLE).
- Сильный штраф большим ошибкам: квадрат усиливает вклад крупных промахов (что бывает полезно, но делает метрику чувствительной к выбросам).

---

### 4. Обучение линейной регрессии

#### Вопрос: Как обучается модель линейной регрессии?
**Ответ:**
Есть два основных подхода:
1) **Аналитическое решение (OLS, метод наименьших квадратов)**:
$$w^* = (X^\top X)^{-1} X^\top y$$
Это работает, если $X^\top X$ обратима (нет сильной линейной зависимости признаков/ранг полный).

2) **Численная оптимизация (градиентный спуск и вариации)**:
- задаём функцию потерь (обычно MSE),
- считаем градиенты по $w$ и $b$,
- итеративно обновляем параметры:
$$w \leftarrow w - \eta \nabla_w \text{MSE}, \quad b \leftarrow b - \eta \nabla_b \text{MSE}$$
где $\eta$ — learning rate. Этот подход удобен на больших данных (SGD/mini-batch), и когда добавляется регуляризация.

#### Вопрос: Что представляет собой предсказание линейной регрессии?
**Ответ:**
Предсказание — это линейная комбинация признаков с весами плюс смещение:
$$\hat{y} = w^\top x + b$$
Если признаки масштабированы, веса легче сравнивать между собой. Если признаки не масштабированы, коэффициенты часто отражают масштаб признаков, а не “важность”.

---

### 5. Проблемы и ограничения линейной регрессии

#### Вопрос: В чём заключаются основные проблемы линейной регрессии?
**Ответ:**
- Линейность по признакам: модель плохо приближает сложные нелинейные зависимости без инженерии признаков.
- Чувствительность к выбросам: MSE сильно штрафует большие ошибки, поэтому выбросы могут “перетянуть” решение.
- Мультиколлинеарность: сильная корреляция признаков делает оценки коэффициентов нестабильными (веса становятся плохо определены, могут менять знак/величину при малых изменениях данных).
- Нарушение допущений (в классической статистике): гомоскедастичность, нормальность ошибок и независимость наблюдений важны для корректных доверительных интервалов/значимости.

#### Вопрос: Как можно модифицировать линейную регрессию для работы с нелинейными зависимостями?
**Ответ:**
- Добавить полиномиальные признаки: $x, x^2, x^3$ и т.д.
- Добавить взаимодействия: $x_i x_j$.
- Применить преобразования признаков/таргета: логарифмирование, Box-Cox, сплайны.
Важно: модель остаётся линейной по параметрам, но становится нелинейной по исходным признакам.

---

### 6. Регуляризация и большие веса

#### Вопрос: Какие проблемы возникают при больших значениях весов в линейной регрессии?
**Ответ:**
Большие веса часто означают, что модель пытается “подогнать” шум или компенсировать плохой масштаб/избыточные признаки. Это приводит к:
- переобучению (хуже качество на новых данных),
- высокой чувствительности к небольшим изменениям входа (предсказания становятся нестабильными),
- усилению влияния мультиколлинеарности (коэффициенты могут раздуваться по модулю).

#### Вопрос: Как справляться с большими весами?
**Ответ:**
Используют регуляризацию — добавляют штраф за сложность (обычно за величину весов) в функцию оптимизации.
- L2 (Ridge): штрафует квадраты весов и “сжимает” коэффициенты.
- L1 (Lasso): штрафует модули весов и может занулять часть коэффициентов (делает модель разреженной).
Также важно масштабировать признаки: без стандартизации регуляризация работает “нечестно” (сильнее штрафует веса у признаков маленького масштаба).

---

### 7. Метрики регрессии

#### Вопрос: Какие метрики используются для оценки качества линейной регрессии?
**Ответ:**
- MAE: $\frac{1}{n}\sum |\hat{y}-y|$. Устойчива к выбросам, понятна в единицах таргета.
- MSE: $\frac{1}{n}\sum (\hat{y}-y)^2$. Сильно наказывает большие ошибки.
- RMSE: $\sqrt{\text{MSE}}$. В тех же единицах, что и таргет, но сохраняет “квадратичный” штраф.
- MAPE: $\frac{100\%}{n}\sum \left|\frac{\hat{y}-y}{y}\right|$. Удобна как процент, но плохо работает при $y\approx 0$.
- $R^2$: доля объяснённой дисперсии, показывает относительное качество по сравнению с предсказанием средним.

#### Вопрос: Какая метрика более чувствительна к выбросам: MSE или MAE?
**Ответ:**
MSE более чувствительна, потому что ошибка возводится в квадрат, и большие промахи начинают доминировать в значении метрики. MAE линейно штрафует отклонения, поэтому выбросы влияют меньше.

---

### 8. Регуляризация

#### Вопрос: Чем отличаются L1- и L2-регуляризация?
**Ответ:**
Пусть базовая задача — минимизировать эмпирическую ошибку $Q(w,b)$ (например, MSE). Тогда:

- **Ridge (L2)**:
$$\min_{w,b} \; Q(w,b) + \alpha \sum_{j=1}^{p} w_j^2$$
Эффект: коэффициенты уменьшаются по модулю, но обычно не становятся ровно нулевыми; модель сохраняет все признаки, но снижает их “агрессивность”. Ridge особенно полезен при мультиколлинеарности, потому что делает задачу более устойчивой.

- **Lasso (L1)**:
$$\min_{w,b} \; Q(w,b) + \alpha \sum_{j=1}^{p} |w_j|$$
Эффект: часть коэффициентов может стать ровно 0, то есть Lasso выполняет встроенный отбор признаков и создаёт разреженную модель. Это удобно, когда признаков много и хочется интерпретируемости/сжатия.

Геометрическая интуиция: L2 ограничение задаёт “круг/сферу”, а L1 — “ромб/октаэдр” с острыми углами, поэтому оптимум L1 чаще попадает на оси (то есть некоторые $w_j = 0$).

#### Вопрос: Что такое ElasticNet?
**Ответ:**
ElasticNet — комбинация L1 и L2:
$$\min_{w,b} \; Q(w,b) + \alpha\left(\lambda \sum |w_j| + (1-\lambda)\sum w_j^2\right)$$
Он сочетает разреженность L1 и устойчивость L2. Часто полезен при сильно коррелированных группах признаков: Lasso может “выбрать” один признак из группы, а ElasticNet чаще распределяет веса более стабильно.

---

### 9. Особенности обработки данных

#### Вопрос: Почему важно масштабировать признаки перед использованием линейной регрессии?
**Ответ:**
Масштабирование нужно по двум причинам:
- Для численной устойчивости: оптимизация (градиентный спуск) сходится быстрее, когда признаки одного порядка.
- Для корректной регуляризации: штраф на веса сравним только если признаки стандартизованы; иначе модель будет предпочитать признаки с крупным масштабом, потому что для них нужен меньший вес.

Стандартный вариант — стандартизация (z-score): $x' = (x-\\mu)/\\sigma$. Для устойчивости к выбросам иногда используют RobustScaler (медиана и IQR).

#### Вопрос: Как линейная регрессия обрабатывает категориальные признаки?
**Ответ:**
Линейная регрессия требует числовые признаки, поэтому категории кодируют:
- One-Hot Encoding: для каждой категории отдельный бинарный столбец (хорошо для номинальных признаков без порядка).
- Ordinal/Label Encoding: категории заменяются числами (подходит только если есть естественный порядок; иначе модель может “придумать” ложную монотонность).
Важно избегать dummy trap (полной линейной зависимости one-hot столбцов): обычно одну категорию выбрасывают (reference category).

---

### 10. Интерпретация результатов

#### Вопрос: Как интерпретировать коэффициенты линейной регрессии?
**Ответ:**
Коэффициент $w_j$ показывает, на сколько изменится $\\hat{y}$ при увеличении $x_j$ на 1, если остальные признаки фиксированы. Это “ceteris paribus” интерпретация, корректна при отсутствии сильной мультиколлинеарности и при адекватной спецификации модели.

При стандартизованных признаках коэффициенты сравнимы по масштабу: больше $|w_j|$ — сильнее вклад (в линейном смысле). При не стандартизованных признаках сравнение $|w_j|$ часто некорректно.

#### Вопрос: Что такое $R^2$ и как его интерпретировать?
**Ответ:**
$R^2$ показывает долю дисперсии $y$, объяснённую моделью: 
$$R^2 = 1 - \frac{\sum (y_i-\hat{y}_i)^2}{\sum (y_i-\bar{y})^2}$$
- $R^2 = 1$: идеальное совпадение.
- $R^2 = 0$: не лучше, чем предсказывать среднее $\\bar{y}$.
- Может быть отрицательным на тесте, если модель хуже baseline (например, при переобучении).

---

### 11. Диагностика модели

#### Вопрос: Как проверить наличие мультиколлинеарности в данных?
**Ответ:**
- Корреляционная матрица: высокая корреляция между признаками — сигнал проблемы (но мультиколлинеарность бывает и при комбинациях >2 признаков).
- VIF (Variance Inflation Factor): для признака $x_j$ строят регрессию $x_j$ на остальные признаки и считают:
  $$\text{VIF}_j = \frac{1}{1 - R_j^2}$$
  Чем больше $R_j^2$, тем сильнее $x_j$ объясняется другими признаками, тем больше VIF. Практическое правило: VIF > 5 (или > 10) — серьёзная мультиколлинеарность.

#### Вопрос: Какие графики помогают проверить качество линейной регрессии?
**Ответ:**
- Residual plot (остатки vs предсказания): помогает увидеть нелинейность, гетероскедастичность, систематические ошибки.
- QQ-plot остатков: проверяет отклонения распределения ошибок от нормального (важно для статистических выводов).
- Факт vs прогноз: визуально показывает смещения и “разброс” вокруг диагонали.
- Остатки vs отдельные признаки: показывает, не осталась ли зависимость, которую модель не объяснила.

#### Вопрос: Что такое мультиколлинеарность и как с ней бороться?
**Ответ:**
**Мультиколлинеарность** — наличие сильной линейной зависимости между признаками (когда один признак можно выразить как линейную комбинацию других или почти выразить). Последствия:
- Оценки коэффициентов становятся нестабильными: небольшие изменения данных могут сильно менять $w$.
- Интерпретация коэффициентов ухудшается: признаки “делят” между собой объясняющую способность, знак и величина весов могут выглядеть странно.
- В случае строгой линейной зависимости $X^\top X$ становится необратимой, и аналитическое OLS-решение $(X^\top X)^{-1} X^\top y$ неприменимо.

**Как бороться:**
- Удалять/объединять коррелированные признаки (feature selection, доменные агрегации).
- Использовать регуляризацию:
  - Ridge стабилизирует решение и хорошо работает при коррелированных признаках.
  - Lasso может занулить часть признаков, но при сильной корреляции может выбирать “случайный” признак из группы.
  - ElasticNet часто наиболее практичен при группах коррелированных признаков.
- Применять методы снижения размерности: PCA (заменить признаки на ортогональные компоненты).
- Правильно кодировать категории (избегать полной линейной зависимости в one-hot).
- Собирать больше данных или улучшать дизайн признаков, если мультиколлинеарность вызвана искусственными/дублирующими фичами.

## Логистическая регрессия

### 1. Основные концепции

#### Вопрос: Что такое логистическая регрессия?
**Ответ:**
Логистическая регрессия — это алгоритм бинарной классификации, который используется для прогнозирования вероятности принадлежности объекта к определённому классу (например, 0 или 1). Она преобразует линейную комбинацию входных признаков в число от 0 до 1 с помощью логистической (сигмоидной) функции.

#### Вопрос: В чём разница между логистической и линейной регрессией?
**Ответ:**
1.  **Тип предсказания**: Линейная регрессия предсказывает непрерывные значения (например, цену), а логистическая — вероятность принадлежности к классу.
2.  **Функция активации**: Логистическая регрессия использует сигмоиду $\sigma(z) = \frac{1}{1 + e^{-z}}$ для сжатия выхода в диапазон $[0, 1]$.
3.  **Функция потерь**: В линейной регрессии минимизируется MSE (среднеквадратичная ошибка), а в логистической — LogLoss (перекрёстная энтропия), так как задача сводится к максимизации правдоподобия.

#### Вопрос: Как получить логистическую регрессию из линейной?
**Ответ:**
Чтобы получить логистическую регрессию, нужно взять результат линейной модели $z = w^\top x + b$ и подставить его в сигмоидную функцию.
Таким образом, линейная модель используется как аргумент для нелинейного преобразования:
$$\hat{p} = \sigma(w^\top x + b) = \frac{1}{1 + e^{-(w^\top x + b)}}$$

---

### 2. Математическая модель

#### Вопрос: Как выглядит формула логистической регрессии?
**Ответ:**
Вероятность принадлежности объекта к положительному классу (1) выражается формулой:
$$P(y=1 \mid x) = \sigma(w^\top x + b) = \frac{1}{1 + e^{-(w^\top x + b)}}$$

#### Вопрос: Что такое логит (logit)?
**Ответ:**
Логит — это натуральный логарифм отношения шансов (odds). Если $P$ — вероятность положительного класса, то:
$$\text{logit}(P) = \ln\left(\frac{P}{1-P}\right) = w^\top x + b$$
Логит линеен относительно признаков, что и позволяет использовать методы линейных моделей для классификации.

---

### 3. Обучение модели и Функция потерь

#### Вопрос: Как обучается логистическая регрессия?
**Ответ:**
Модель обучается методом максимизации правдоподобия, что эквивалентно минимизации логистической функции потерь (LogLoss / Binary Cross-Entropy). Для поиска минимума обычно используют градиентный спуск или его модификации (SGD, Adam).

#### Вопрос: Как выглядит формула кросс-энтропии (Binary Cross Entropy)?
**Ответ:**
Для одного объекта формула выглядит так:
$$L(y, \hat{y}) = - \big[\, y \cdot \ln(\hat{y}) + (1 - y)\cdot \ln(1 - \hat{y}) \,\big]$$
Для всей выборки из $N$ объектов (усреднённая ошибка):
$$\text{Loss} = -\frac{1}{N} \sum_{i=1}^{N} \big[\, y_i \ln(\hat{y}_i) + (1 - y_i) \ln(1 - \hat{y}_i) \,\big]$$
*   Если истинный класс $y=1$, минимизируется $-\ln(\hat{y})$ (штрафуем, если $\hat{y}$ далеко от 1).
*   Если истинный класс $y=0$, минимизируется $-\ln(1-\hat{y})$ (штрафуем, если $\hat{y}$ далеко от 0).

---

### 4. Оценка статистической значимости (Пример)

### Вопрос: Как проверить статистическую значимость коэффициентов?
**Ответ:**
Используется **z-тест** (тест Вальда). Нулевая гипотеза $H_0$: коэффициент $\beta_j = 0$ (признак не влияет на целевую переменную).
Алгоритм:
1.  Рассчитать стандартную ошибку коэффициента (SE).
2.  Найти z-статистику: $z = \dfrac{\beta_j}{SE(\beta_j)}$.
3.  Найти p-value. Если p-value < 0.05 (обычно), коэффициент значим.

#### Пример расчёта (на основе слайдов):
**Дано:**
*   Модель предсказывает покупку продукта ($y=1$).
*   Коэффициент цены $\beta_1 = -0.5$.
*   Выборка $N = 100$.
*   Значения признака $x_1$ (цена): $[5, 10, \dots, 50]$.
*   Предсказанная вероятность $p_i \approx 0.5$ для большинства точек (упрощение для расчёта дисперсии).

**Шаг 1: Расчёт стандартной ошибки (SE)**
Формула дисперсии коэффициента (упрощённая через гессиан):
$$\text{Var}(\beta_1) = \frac{1}{\sum p_i (1-p_i) x_{1,i}^2}$$
Подставим значения:
*   $p_i (1-p_i) \approx 0.25$
*   Сумма квадратов признака $\sum x_{1,i}^2 = 5525$
*   $\text{Var}(\beta_1) \approx \dfrac{1}{0.25 \cdot 5525} \approx 0.000724$
*   $SE(\beta_1) \approx \sqrt{0.000724} \approx 0.027$

**Шаг 2: Расчёт z-статистики**
$$z = \frac{-0.5}{0.027} \approx -18.5$$

**Шаг 3: Вывод**
Значение $z \approx -18.5$ соответствует ничтожно малому p-value ($p \ll 0.05$).
**Заключение:** Коэффициент цены статистически значим.

---

### 5. Особенности и метрики

#### Вопрос: Какие предположения делает логистическая регрессия?
**Ответ:**
1.  **Линейность логита**: Зависимость между логарифмом шансов и признаками линейная.
2.  **Независимость наблюдений**: Объекты в выборке не должны зависеть друг от друга.
3.  **Отсутствие мультиколлинеарности**: Признаки не должны сильно коррелировать между собой.

#### Вопрос: Какие метрики применяются для оценки?
**Ответ:**
*   **Accuracy**: Доля правильных ответов (плоха при дисбалансе классов).
*   **Precision (Точность)**: Доля реальных "единиц" среди всех, кого модель назвала "единицами".
*   **Recall (Полнота)**: Доля найденных "единиц" среди всех реальных "единиц".
*   **F1-score**: Гармоническое среднее Precision и Recall. Используется, когда важен баланс между точностью и полнотой.
    $$F1 = \frac{2 \cdot \text{Precision} \cdot \text{Recall}}{\text{Precision} + \text{Recall}}$$
*   **ROC-AUC**: Оценивает способность модели ранжировать объекты (отделять классы при разных порогах).

---

### 6. Мультиклассовая классификация

#### Вопрос: Как логистическая регрессия работает с несколькими классами?
**Ответ:**
Логистическая регрессия — бинарный классификатор, но её адаптируют для $K$ классов с помощью стратегий:

##### 1. One-vs-All (Один против всех / OvA)
*   **Метод**: Обучаем $K$ моделей. Каждая модель учится отличать **класс $k$** от **всех остальных**.
*   **Прогноз**: Выбираем класс, модель которого выдала наибольшую вероятность.
*   **Плюсы**: Простота, нужно обучить всего $K$ моделей.
*   **Минусы**: Возможен дисбаланс данных (одного класса всегда меньше, чем "всех остальных").

##### 2. All-vs-All (Каждый против каждого / OvO)
*   **Метод**: Строим модель для каждой **пары** классов. Всего $K(K-1)/2$ моделей.
*   **Прогноз**: Голосование. Прогоняем объект через все модели; побеждает класс, набравший больше всего побед в парных дуэлях.
*   **Плюсы**: Лучшее разделение границ между конкретными парами классов.
*   **Минусы**: Большое количество моделей при росте числа классов (вычислительно дорого).

#### Вопрос: Как справляться с дисбалансом классов?
**Ответ:**
*   **Взвешивание классов (class_weights)**: В функцию потерь добавляют веса, штрафующие за ошибку на редком классе сильнее.
*   **Ресемплинг**: Oversampling (размножение редкого класса, например SMOTE) или Undersampling (удаление примеров частого класса).
*   **Выбор метрик**: Использовать F1-score или PR-кривую вместо Accuracy.


## Метод опорных векторов (SVM)

### 1. Основная идея метода опорных векторов (SVM)

#### Вопрос: Что такое SVM, и как он работает?
**Ответ:**
SVM (Support Vector Machine) — это алгоритм машинного обучения для задач классификации (и регрессии). Его основная цель — найти гиперплоскость, которая лучше всего разделяет объекты разных классов.

**Ключевая идея:**
SVM ищет не просто «какую-то» границу, которая разделяет классы, а ту, которая максимизирует **зазор (margin)** между ближайшими точками обоих классов. Эти ближайшие точки называются **опорными векторами** (support vectors), именно они определяют положение границы. Остальные точки выборки на построение границы не влияют.

---

### 2. Как SVM работает с нелинейными данными

#### Вопрос: Что делать, если классы нельзя разделить прямой линией?
**Ответ:**
Если классы линейно неразделимы в исходном пространстве, SVM использует трюк с **ядрами (kernel trick)**. Ядра позволяют неявно отобразить данные в пространство более высокой размерности, где классы становятся линейно разделимыми.

**Популярные ядра:**
*   **Линейное (Linear)**: для простых, линейно разделимых задач.
*   **Полиномиальное (Polynomial)**: добавляет степени и произведения признаков (например, $x_1^2$, $x_1 x_2$).
*   **Радиальное базисное (RBF)**: самое популярное, позволяет строить границы очень сложной формы (эквивалентно отображению в бесконечномерное пространство).

---

### 3. Отличия SVM и логистической регрессии

#### Вопрос: Чем отличается SVM от логистической регрессии?
**Ответ:**

| Характеристика    | Логистическая регрессия                          | SVM                                      |
|-------------------|--------------------------------------------------|------------------------------------------|
| **Цель**          | Предсказывает вероятность принадлежности к классу | Максимизирует геометрический зазор между классами |
| **Функция потерь**| Log Loss (Cross Entropy)                         | Hinge Loss                               |
| **Интерпретация** | Хороша для анализа влияния признаков и вероятностей | Ориентирована на жесткую классификацию (класс 1 или -1) |
| **Выбросы**       | Чувствительна (пытается минимизировать ошибку на всех точках) | Более устойчива (граница зависит только от опорных векторов) |
| **Производительность** | Быстрее обучается, хорошо работает на больших данных | Медленнее на больших выборках (часто \(O(n^2)\)–\(O(n^3)\) для ядрового SVM) |


#### Вопрос: Почему SVM стремится к максимальному зазору между классами?

**Ответ:**
Широкий зазор делает модель более устойчивой к шуму и улучшает её обобщающую способность. Если граница проходит «вплотную» к данным, то даже небольшое изменение новой точки (шум) может выбросить её на «чужую» сторону. Максимальный зазор снижает этот риск.

---

### 4. Функция потерь в SVM

#### Вопрос: Как SVM оценивает ошибки?

**Ответ:**
SVM использует функцию потерь **Hinge Loss**:
$$L = \max\bigl(0,\; 1 - y \cdot f(x)\bigr), \quad f(x)=w^\top x + b,\; y\in\{-1,1\}$$
где $y$ — истинный класс, а $f(x)$ — выход модели (расстояние до разделяющей плоскости).

**Как это работает:**
1.  Если объект классифицирован верно и лежит за пределами зазора ($y f(x) \ge 1$), штраф равен **0**. Модели «всё равно» на такие точки.
2.  Если объект находится внутри зазора ($0 < y f(x) < 1$) или классифицирован неверно ($y f(x) \le 0$), штраф растёт линейно.

---

### 5. Регуляризация в SVM

#### Вопрос: За что отвечает гиперпараметр C?
**Ответ:**
В SVM оптимизируется функционал:
$$\min_{w,b}\; \frac{1}{2}\|w\|_2^2 \;+\; C \sum_{i} \max\bigl(0,\; 1 - y_i (w^\top x_i + b)\bigr)$$
Параметр **C** контролирует баланс между шириной зазора и ошибками классификации на обучающей выборке:

*   **Малое C**: Модель допускает больше ошибок классификации, но строит **более широкий зазор**. Это делает границу более гладкой и простой (защита от переобучения, soft margin).
*   **Большое C**: Модель старается классифицировать **все** обучающие примеры правильно, даже если зазор станет очень узким или сложным. Это повышает риск переобучения (hard margin поведение).

---

### 6. Применение и особенности

#### Вопрос: Когда использовать SVM?
**Ответ:**
**Стоит использовать SVM, если:**
*   Данных немного или среднее количество (до 50-100 тыс.), но много признаков.
*   Нужна высокая точность классификации, а вероятности не так важны.
*   Данные имеют сложную структуру, которую можно разделить с помощью ядер (RBF).

**Не стоит использовать SVM, если:**
*   Данных очень много (миллионы) — алгоритм будет обучаться слишком долго.
*   Много шума и перекрывающихся классов — SVM будет сильно переобучаться без тщательного подбора C.
*   Критически важна вероятностная интерпретация (хотя в sklearn есть `probability=True`, это замедляет работу).

#### Вопрос: Как SVM работает с несбалансированными данными?
**Ответ:**
Стандартный SVM может плохо работать с дисбалансом, так как просто минимизирует общую ошибку.
**Решение:** использовать параметр `class_weight='balanced'`, который назначает больший штраф (C) за ошибку на миноритарном классе. Это заставляет границу сдвигаться в сторону мажоритарного класса, чтобы не упускать редкие примеры.

---

### 7. Пример выбора между SVM и логистической регрессией

#### Вопрос: У меня миллион данных, что выбрать: SVM или логистическую регрессию?
**Ответ:**
Лучше выбрать **логистическую регрессию**.
*   **Причина:** Логистическая регрессия обучается линейно (или почти линейно) от размера данных и легко распараллеливается (SGD). SVM с нелинейными ядрами требует вычисления матрицы расстояний, что на миллионе примеров займёт слишком много памяти и времени.
*   **Исключение:** Если использовать линейный SVM (LinearSVC), он по скорости сопоставим с логистической регрессией, но тогда теряется преимущество ядер.


## Регуляризация

### 1. Основные понятия

#### Вопрос: Что такое регуляризация и зачем она нужна?
**Ответ:**
Регуляризация — это метод борьбы с переобучением (overfitting), который добавляет штраф за сложность модели к функции потерь. Сложность обычно измеряется величиной коэффициентов (весов).

**Зачем нужна:**
*   **Предотвращение переобучения**: Не даёт модели «запоминать» шум в данных, ограничивая рост весов.
*   **Улучшение обобщения**: Заставляет модель искать более простые закономерности, которые лучше работают на новых данных.
*   **Борьба с мультиколлинеарностью**: Позволяет находить устойчивое решение, даже если признаки сильно коррелируют (особенно L2).

#### Вопрос: Почему ограничивающие плоскости у регуляризаций имеют такую форму?
**Ответ:**
Это связано с геометрическим смыслом норм:
*   **L2 (Ridge)**: Ограничение имеет вид $w_1^2 + w_2^2 = R^2$. В 2D это уравнение **окружности**. Когда линии уровня функции потерь (эллипсы) касаются этой окружности, точка касания может быть где угодно на дуге, но редко ровно на оси.
*   **L1 (Lasso)**: Ограничение имеет вид $|w_1| + |w_2| = R$. В 2D это уравнение **ромба (квадрата, повёрнутого на 45°)**. У ромба есть «острые» углы на осях координат. Линии уровня функции потерь с большой вероятностью коснутся ромба именно в вершине (на оси), где одна из координат равна нулю.

---

### 2. Виды регуляризации

#### Вопрос: Какая разница между регуляризацией L1 и L2?
**Ответ:**

| Характеристика        | L1 (Lasso)                                           | L2 (Ridge)                                                |
| --------------------- | ---------------------------------------------------- | --------------------------------------------------------- |
| **Формула штрафа**    | $$(\alpha \sum \|w_j\|)$$                            | $$(\alpha \sum w_j^2)$$                                   |
| **Форма ограничения** | Ромб (острые углы)                                   | Окружность (гладкая)                                      |
| **Влияние на веса**   | Может занулять веса полностью (делает их равными 0)  | Уменьшает веса, стремясь к 0, но редко делает их точно 0  |
| **Отбор признаков**   | Да (встроенный feature selection)                    | Нет (использует все признаки с малыми весами)             |
| **Применение**        | Когда нужно отобрать важные признаки (разреженность) | Когда важна стабильность и борьба с мультиколлинеарностью |


### 3. Механика работы

#### Вопрос: Как работают L1 и L2 регуляризации (через градиенты)?
**Ответ:**
Это хорошо видно через производные штрафа по весу $w_j$:

**Для L2 (Ridge):**
Штраф $\frac{\alpha}{2}\sum w_j^2$. Производная: $\alpha w_j$.
*   Градиент пропорционален самому весу.
*   Если вес большой — штраф сильный.
*   Если вес маленький (близок к 0) — штраф тоже становится микроскопическим. Поэтому оптимизатору нет стимула дожимать вес ровно до 0, он просто делает его очень малым.

**Для L1 (Lasso):**
Штраф $\alpha \sum |w_j|$. Производная (субградиент): $\alpha \cdot \text{sign}(w_j)$ (либо $+\alpha$, либо $-\alpha$, либо $[-\alpha, +\alpha]$ при $w_j=0$).
*   Градиент **постоянен** (не зависит от величины веса, пока $w_j \ne 0$).
*   Даже если вес очень маленький (например, 0.0001), штраф всё равно толкает его к нулю с постоянной силой $\alpha$. Это позволяет «дожать» вес ровно до 0 и исключить признак.

#### Вопрос: Как Elastic Net объединяет свойства L1 и L2 регуляризаций?
**Ответ:**
Elastic Net комбинирует оба штрафа в функции потерь:
$$\alpha_1 \|w\|_1 + \alpha_2 \|w\|_2^2$$
*   От **L1** он берёт способность занулять веса (отбор признаков).
*   От **L2** он берёт стабильность (группировка коррелированных признаков).
*   **Когда полезен:** Если есть группа сильно коррелированных признаков, Lasso (L1) выберет один случайный и обнулит остальные. Elastic Net скорее присвоит им всем ненулевые (хоть и уменьшенные) веса, что часто надёжнее.

---

### 4. Практические аспекты

#### Вопрос: Как выбрать между L1 и L2 регуляризациями?
**Ответ:**
1.  **L1 (Lasso)**: Если подозреваете, что **многие признаки — мусор**, и на результат влияют только несколько ключевых факторов. Идеально для моделей, которые нужно потом интерпретировать («какие 5 параметров важны?»).
2.  **L2 (Ridge)**: Если **все признаки могут быть важны** (хоть и по чуть-чуть), или если признаков немного, но данные зашумлены. Стандартный выбор «по умолчанию».
3.  **Elastic Net**: Если признаков очень много, они коррелируют, и вы не знаете точно, какая регуляризация лучше. Универсальный, но требует подбора двух гиперпараметров.

#### Вопрос: Что такое гиперпараметр $\lambda$ (или $\alpha$), и как его выбирать?
**Ответ:**
Гиперпараметр $\lambda$ определяет силу регуляризации.
*   **Малое $\lambda$**: Модель почти как обычная (без штрафа), риск переобучения.
*   **Большое $\lambda$**: Сильный штраф, веса стремятся к 0. Риск недообучения (модель становится слишком простой, константной).

**Как выбирать:**
Только через кросс-валидацию (например, `GridSearchCV` или `RidgeCV`/`LassoCV`). Нельзя подбирать на обучающей выборке. Строят график зависимости ошибки на валидации от $\lambda$ и ищут минимум.

---

### 5. Дополнительные методы борьбы с переобучением

#### Вопрос: Какие ещё методы помогают бороться с переобучением, кроме регуляризации?
**Ответ:**
1.  **Увеличение данных**: Собрать больше примеров или использовать аугментацию (искусственное расширение датасета).
2.  **Упрощение модели**: Уменьшить число признаков, уменьшить глубину деревьев, число слоев нейросети.
3.  **Early Stopping (Ранняя остановка)**: Прекратить обучение, как только ошибка на валидационной выборке перестала падать и начала расти.
4.  **Dropout** (для нейросетей): Случайное выключение нейронов в процессе обучения — работает как ансамбль многих прореженных сетей.

## Метрики качества в машинном обучении

### 1. Различие между Функцией потерь и Метрикой

#### Вопрос: Чем отличается метрика от Loss (функции потерь)?
**Ответ:**
Хотя и loss, и метрика оценивают ошибку, они служат разным целям и применяются на разных этапах:

1.  **Loss-функция (Функционал качества)**:
    *   **Где используется**: Непосредственно в процессе **обучения** (оптимизации) модели.
    *   **Свойства**: Должна быть **дифференцируемой** (иметь производную), чтобы градиентный спуск мог минимизировать ошибку.
    *   **Пример**: LogLoss, MSE, Cross-Entropy. Оптимизатору "понятно", как их уменьшать, но бизнесу значение "LogLoss = 0.69" ни о чем не говорит.
2.  **Метрика**:
    *   **Где используется**: Для **финального замера** качества, отбора лучшей модели, презентации результатов заказчику.
    *   **Свойства**: Должна быть **интерпретируемой** и понятной человеку. Не обязана быть гладкой или дифференцируемой.
    *   **Пример**: Accuracy (точность в %), Precision (сколько денег мы сберегли), F1-score.

**Итог**: Мы обучаем модель, минимизируя *Loss*, чтобы в итоге получить высокую *Метрику*.

---

### 2. Метрики регрессии

#### Вопрос: Какие основные метрики используются для оценки моделей регрессии?
**Ответ:**
Основные метрики оценивают отклонение предсказанного значения $\hat{y}$ от реального $y$.

##### 1. MAE (Mean Absolute Error — Средняя абсолютная ошибка)
*   **Формула**:
    $$\text{MAE} = \frac{1}{n}\sum_{i=1}^{n} \bigl|\hat{y}_i - y_i\bigr|$$
*   **Смысл**: Показывает средний размер ошибки в абсолютных единицах исходных данных (например, "ошибаемся в среднем на 10 рублей").
*   **Плюсы**: Легко интерпретировать; устойчива к выбросам (не штрафует их слишком сильно).
*   **Минусы**: Производная не определена в нуле (сложнее использовать как Loss), одинаково относится к малым и большим ошибкам.

##### 2. MSE (Mean Squared Error — Среднеквадратичная ошибка)
*   **Формула**:
    $$\text{MSE} = \frac{1}{n}\sum_{i=1}^{n} \bigl(\hat{y}_i - y_i\bigr)^2$$
*   **Смысл**: Усредняет квадраты ошибок.
*   **Плюсы**: Сильно штрафует за большие ошибки (выбросы). Полезна, если критично не допускать крупных промахов.
*   **Минусы**: Размерность — "квадратные единицы" (например, "квадратные рубли"), что сложно интерпретировать.

##### 3. RMSE (Root Mean Squared Error — Корень из среднеквадратичной ошибки)
*   **Формула**: $$\text{RMSE} = \sqrt{\text{MSE}}$$
*   **Смысл**: То же, что MSE, но возвращает размерность к исходным единицам.
*   **Сравнение**: RMSE всегда $\ge$ MAE. Чем больше разница между RMSE и MAE, тем больше в данных выбросов.

##### 4. MAPE (Mean Absolute Percentage Error — Средняя абсолютная ошибка в процентах)
*   **Формула**:
    $$\text{MAPE} = \frac{100\%}{n}\sum_{i=1}^{n} \left|\frac{\hat{y}_i - y_i}{y_i}\right|$$
*   **Смысл**: Показывает ошибку в процентах (например, "ошибаемся на 6.1%").
*   **Плюсы**: Удобна для бизнеса и сравнения моделей на разных масштабах данных.
*   **Минусы**: Не работает, если $y_i = 0$ (деление на ноль). Становится огромной, если $y_i$ близок к нулю.

##### 5. $R^2$ (Коэффициент детерминации)
*   **Формула**: $$R^2 = 1 - \frac{\sum (\hat{y}_i - y_i)^2}{\sum (y_i - \bar{y})^2}$$
*   **Смысл**: Доля дисперсии (разброса) данных, которую объяснила модель.
    *   $R^2 = 1$: Идеал.
    *   $R^2 = 0$: Модель работает как предсказание среднего.
    *   $R^2 < 0$: Модель хуже, чем константный прогноз (переобучение или ошибка).

#### Вопрос: Какая метрика чувствительнее к выбросам: MSE или MAE?
**Ответ:**
**MSE** (и RMSE) гораздо чувствительнее.
*   **Причина**: Возведение в квадрат. Если ошибка на одном объекте выросла в 10 раз, штраф MSE вырастет в 100 раз.
*   **Вывод**: Если важно учесть большие ошибки — выбирайте MSE/RMSE. Если нужно игнорировать редкие аномалии — выбирайте MAE.

---

### 3. Метрики классификации (Бинарная)

#### Вопрос: Что такое Confusion Matrix (Матрица ошибок)?
**Ответ:**
Это таблица 2x2, показывающая результаты сравнения прогноза с фактом:
*   **TP (True Positive)**: Верно предсказанные "1".
*   **TN (True Negative)**: Верно предсказанные "0".
*   **FP (False Positive)**: Ложная тревога (сказали 1, а там 0).
*   **FN (False Negative)**: Пропуск цели (сказали 0, а там 1).

#### Вопрос: Какие основные метрики существуют (Accuracy, Precision, Recall)?
**Ответ:**

1.  **Accuracy (Точность)**
    *   **Формула**: $$\text{Accuracy} = \frac{TP + TN}{TP + TN + FP + FN}$$
    *   **Проблема**: Бесполезна при дисбалансе. Если 99% объектов — класс 0, то константная модель даст 99% Accuracy, но не найдет ни одного объекта класса 1.

2.  **Precision (Точность)**
    *   **Формула**: $$\text{Precision} = \frac{TP}{TP + FP}$$ (доля реальных 1 среди всех предсказанных 1).
    *   **Когда важна**: Когда высока цена **ложной тревоги (FP)**.
    *   **Пример**: Спам-фильтр. Лучше пропустить спам (FN), чем отправить важное письмо в спам (FP).

3.  **Recall (Полнота)**
    *   **Формула**: $$\text{Recall} = \frac{TP}{TP + FN}$$ (какую долю класса 1 мы нашли).
    *   **Когда важна**: Когда высока цена **пропуска (FN)**.
    *   **Пример**: Медицина (рак) или поиск мошенников. Лучше перепроверить здорового (FP), чем пропустить больного (FN).

#### Вопрос: Расскажите про F1-Score и способы усреднения.
**Ответ:**
**F1-Score** — это **среднее гармоническое** между Precision и Recall:
$$F1 = \frac{2 \cdot \text{Precision} \cdot \text{Recall}}{\text{Precision} + \text{Recall}}$$

**Почему гармоническое?**
*   Арифметическое среднее (Precision + Recall)/2 может скрыть провал одной из метрик.
*   Гармоническое среднее стремится к **меньшему** из значений. Если Recall = 0, то и F1 = 0. Это заставляет модель держать баланс.

**F-beta Score ($F_\beta$)**:
Позволяет сместить приоритет.
*   $\beta > 1$: Важнее Recall.
*   $\beta < 1$: Важнее Precision.

---

### 4. Продвинутые метрики (ROC-AUC и PR-AUC)

#### Вопрос: Что такое ROC-AUC и PR-AUC?

##### 1. ROC-AUC (Area Under ROC Curve)
*   **Оси**: Y — TPR (Recall), X — FPR (доля ложных срабатываний среди всех 0).
*   **Смысл**: Оценивает способность модели **ранжировать** объекты. Вероятность того, что случайный объект класса 1 получит оценку выше, чем случайный объект класса 0.
*   **Свойства**:
    *   Диапазон [0.5, 1.0]. 0.5 — случайно, 1 — идеально.
*   **Устойчива к масштабу**: Если все предсказания поделить на 2 или взять логарифм, порядок не изменится — ROC-AUC не изменится.
    *   **Устойчива к балансу классов**: ROC-AUC не изменится, если продублировать выборку негативных примеров в 10 раз (TPR и FPR — относительные величины).

##### 2. PR-AUC (Area Under Precision-Recall Curve)
*   **Оси**: Y — Precision, X — Recall.
*   **Смысл**: Показывает баланс точности и полноты при разных порогах.
*   **Отличие**: Очень чувствительна к дисбалансу. Если класс 1 редкий, а модель делает много FP ошибок, Precision резко падает, и PR-AUC снижается.

#### Вопрос: Какую метрику выбрать при дисбалансе классов?
**Ответ:**
*   **ROC-AUC** может быть **оптимистичной**. Пример: из 1000 объектов всего 50 — класс 1. Модель нашла 15, но сделала 100 ошибок FP. ROC-AUC будет высоким (т.к. FPR все равно мал из-за огромного числа TN), создавая иллюзию успеха.
*   **PR-AUC** в этом случае будет низким, так как Precision (15 / 115) будет ужасным.
*   **Вывод**: При сильном дисбалансе и интересе к малому классу (Fraud detection) используйте **PR-AUC**.

---

### 5. Многоклассовая классификация: Micro vs Macro

#### Вопрос: В чем разница между Micro и Macro усреднением?
**Ответ:**
Когда классов > 2, метрики считаются через агрегацию:

##### 1. Micro-averaging (Микро-усреднение)
*   **Метод**: Складываем все TP, FP, FN по всем классам в одну общую кучу, затем считаем метрику по общим суммам.
*   **Особенность**: Вклад класса пропорционален его размеру.
*   **Применение**: Если важна **общая эффективность** системы, и ошибки на больших классах важнее, чем на редких.

##### 2. Macro-averaging (Макро-усреднение)
*   **Метод**: Считаем метрику (Precision/Recall) для **каждого класса отдельно**, а потом берем среднее арифметическое этих метрик.
*   **Особенность**: Все классы равноправны. Маленький класс (10 объектов) влияет на метрику так же, как большой (1000 объектов).
*   **Применение**: Если нам важно качество работы алгоритма на **всех** классах, даже самых редких.

**Пример из слайда**:
*   Есть большой класс (130 TN) и маленькие классы.
*   Если модель плохо работает на маленьких классах, **Macro**-метрика это сразу покажет (упадет).
*   **Micro**-метрика может остаться высокой за счет хороших предсказаний на мажоритарном классе.


## Деревья решений (Decision Trees): Полный разбор

### 1. Определение и Принцип работы

#### Вопрос: Что такое дерево решений и как оно работает?
**Ответ:**
Дерево решений — это алгоритм, моделирующий процесс принятия решений через иерархическую структуру правил. Процесс прогнозирования напоминает игру в "20 вопросов" или медицинскую диагностику.

**Структура дерева**:
1.  **Корень (Root Node)**: Верхний узел, содержащий всю выборку. С него начинается анализ.
2.  **Внутренние вершины (Предикаты)**: Узлы, проверяющие определённое условие (правило разбиения).
    *   *Пример*: "Возраст > 40 лет?".
    *   В зависимости от ответов ("Да" или "Нет") объект направляется в левую или правую ветвь.
3.  **Листья (Leaf Nodes)**: Конечные вершины, не имеющие потомков. Здесь принимается финальное решение.

**Механизм прогноза**:
*   Объект начинает путь в корне.
*   В каждом узле проверяется условие.
*   Объект "проваливается" вниз до тех пор, пока не попадет в лист.
*   **Прогноз листа**:
    *   *Классификация*: Класс, доминирующий в этом листе (или вероятность классов).
    *   *Регрессия*: Среднее значение целевой переменной объектов, попавших в этот лист.

---

### 2. Жадный алгоритм построения (ID3, CART)

#### Вопрос: Как именно строится дерево? (Пошаговый алгоритм)
**Ответ:**
Деревья строятся с помощью **жадного алгоритма** (Greedy Algorithm). Суть "жадности" в том, что на каждом шаге выбирается разбиение, которое максимально улучшает метрику качества **прямо сейчас**, без попытки предугадать, будет ли это выгодно через 3 шага.

**Алгоритм (рекурсивный)**:
1.  **Шаг 1**: Начинаем с вершины (изначально корень).
2.  **Шаг 2 (Перебор)**: Перебираем **все** доступные признаки и для каждого признака — **все** возможные пороги разбиения.
3.  **Шаг 3 (Оценка)**: Для каждого кандидата "Признак + Порог" вычисляем критерий качества (насколько хорошо это разбиение упорядочивает данные).
4.  **Шаг 4 (Выбор)**: Выбираем **лучшее** разбиение (с максимальным Information Gain).
5.  **Шаг 5 (Разделение)**: Делим объекты на две группы (Left и Right).
6.  **Шаг 6 (Рекурсия)**: Повторяем шаги 2–5 для каждой новой группы, пока не сработает критерий остановки (Stop Criterion).

**Пример из слайдов**:
*   *Корень*: Имеем смешанную выборку (11 объектов, таргет разный).
*   *Сплит 1*: "Возраст > 40?". Делит на две группы. В правой ветке оказалось 3 объекта, и они все одного класса.
*   *Решение*: Правую ветку объявляем листом (прогноз готов). Левую ветку продолжаем делить дальше ("Цель кредита — бизнес?").

---

### 3. Критерии информативности (Математика)

#### Вопрос: Как измерить "хаотичность" данных? (Энтропия и Джини)
**Ответ:**
Чтобы выбрать лучший сплит, нужно число, описывающее степень беспорядка в узле.

##### 1. Энтропия Шеннона (Entropy)
Мера неопределённости. Чем выше энтропия, тем более разнородны данные.
$$H = -\sum_k p_k \log p_k$$
*   Если в узле 100% объектов одного класса: $H = 0$ (Минимум хаоса).
*   Если 50% на 50% (2 класса): $H = \log 2 \approx 0.693$ (Максимум хаоса).

##### 2. Критерий Джини (Gini Impurity)
Вероятность ошибки при случайной классификации.
$$G = 1 - \sum_k p_k^2$$
*   50/50: $G = 0.5$.
*   Чистый узел: $G = 0$.

##### 3. Критерий для Регрессии (Дисперсия/MSE)
В задачах регрессии хаотичность — это разброс значений вокруг среднего .
$$\text{Var} = \frac{1}{n}\sum_{i}(y_i - \bar{y})^2$$
Мы ищем сплит, который минимизирует **средневзвешенную дисперсию** в дочерних узлах.

#### Вопрос: Как считается Information Gain (Прирост информации)?
**Ответ:**
Это разница между хаосом "До" и взвешенным хаосом "После".
$$IG = H(\text{parent}) - \sum_{c} \frac{n_c}{n_{\text{parent}}} H(c)$$
**Пример расчёта из слайда**:
*   *До*: Энтропия $H(\text{parent})$.
*   *Сплит*: Получили левый узел (Энтропия 0.81) и правый узел (Энтропия 1.0).
*   *Итог*: Взвешенная сумма новых энтропий может оказаться высокой, и $IG$ будет маленьким. Мы ищем такой сплит, где в дочерних узлах энтропия станет 0 или близка к нему.

---

### 4. Особенности работы с признаками

#### Вопрос: Как перебираются пороги для числовых и категориальных признаков?

##### Числовые признаки
*   Сортируем уникальные значения признака: $x_{(1)}, x_{(2)}, \dots$.
*   Проверяем пороги между ними: $\tfrac{x_{(i)} + x_{(i+1)}}{2}$.
*   Для каждого порога считаем IG и берем лучший.
*   *Пример*: Признак {10, 20, 30}. Пороги: 15, 25.

##### Категориальные признаки
*   **Проблема**: Если категорий $m$ много, перебирать все разбиения множества ($2^m$) очень дорого.
*   **Решение (Target Encoding подход)**:
    1.  Для каждой категории считаем статистику по таргету (например, долю класса "1").
    2.  Упорядочиваем категории по этой статистике: $c_{(1)}, c_{(2)}, \dots$.
    3.  Теперь работаем с ними как с числовым признаком: ищем порог, который отделит категории "слева" (с малой долей 1) от категорий "справа" (с большой долей 1).

#### Вопрос: Почему не нужно масштабирование?
**Ответ:**
Деревьям безразличен масштаб и распределение признаков.
*   Условие $x > 10$ для данных в метрах эквивалентно $x_{\text{см}} > 1000$ для данных в сантиметрах. Структура дерева и качество разбиения останутся идентичными.
*   Монотонные преобразования (log, sqrt) также не влияют на дерево.

---

### 5. Проблемы: Переобучение и Экстраполяция

#### Вопрос: Почему деревья переобучаются и как с этим бороться?
**Ответ:**
Дерево стремится свести ошибку на трейне к нулю. Если его не остановить, оно построит уникальный "лист" для каждого выброса или шумового объекта. Такое дерево будет огромным и бесполезным на новых данных.

**Гиперпараметры для регуляризации (Pre-pruning)**:
1.  **max_depth**: Ограничить глубину (например, не глубже 5-10 уровней).
2.  **min_samples_leaf**: Запретить листы размером меньше заданного числа объектов (гарантирует, что правило основано на статистике, а не на единичном случае).
3.  **min_samples_split**: Запретить ветвление узлов, где мало объектов.
4.  **max_leaf_nodes**: Ограничить общее число листьев.

#### Вопрос: Почему деревья плохи в экстраполяции?
**Ответ:**
Дерево — это кусочно-постоянная функция.
*   Если в обучении максимальный возраст был 60 лет (таргет $100k), то для клиента возрастом 80 лет дерево выдаст прогноз как для 60-летнего (значение из крайнего листа).
*   Оно **не умеет продолжать тренд** (линию), как это делает линейная регрессия. Оно просто возвращает среднее значение из "ближайшей известной области".

---

### 6. Важность признаков (Feature Importance)

#### Вопрос: Как дерево оценивает важность признаков?
**Ответ:**
Если признак часто выбирается для сплитов (особенно в верхней части дерева) и эти сплиты дают большой прирост информации (IG), значит, признак важен.
*   **Формула**: Сумма $IG$ для всех узлов, где использовался данный признак, деленная на сумму всех $IG$ дерева.
*   Это позволяет ранжировать признаки по их вкладу в очистку данных от хаоса.

## Ансамблевые методы

### Общие вопросы

#### Вопрос: Какие основные ансамблевые методы с деревьями решений ты знаешь?
**Ответ:**
Основные методы:
1.  **Бэггинг (Bagging)**: Параллельное обучение независимых моделей на случайных подвыборках. Пример: *Случайный лес*. Усреднение снижает разброс (Variance).
2.  **Градиентный бустинг (Gradient Boosting)**: Последовательное обучение, где каждая следующая модель исправляет ошибки предыдущих. Снижает смещение (Bias).
3.  **Стекинг (Stacking)**: Обучение мета-модели, которая принимает на вход прогнозы базовых алгоритмов.

---

### Случайный лес (Random Forest)

#### Вопрос: Что такое случайный лес и как он строится?
**Ответ:**
Случайный лес — это бэггинг над деревьями решений.
**Этапы построения**:
1.  **Bootstrap**: Из обучающей выборки размера $n$ генерируются $n$ случайных подвыборок того же размера $n$ **с возвращением** (некоторые объекты дублируются, некоторые не попадают — Out-of-Bag).
2.  **Независимое обучение**: На каждой подвыборке строится своё дерево.
3.  **Случайные признаки**: При построении дерева в каждом узле перебираются не все признаки, а случайное подмножество (обычно $\sqrt{p}$ для классификации).
4.  **Агрегация**:
    *   *Регрессия*: Усреднение ответов всех деревьев.
    *   *Классификация*: Голосование большинства (Hard Voting) или усреднение вероятностей (Soft Voting).

#### Вопрос: Почему случайный лес устойчив к шуму и выбросам?
**Ответ:**
1.  **Bootstrap**: Выброс попадает лишь в часть подвыборок (~63%). Деревья, обученные без выброса, дадут нормальный прогноз.
2.  **Усреднение**: Ошибка одного дерева (из-за выброса) "гасится" корректными прогнозами сотен других деревьев.

#### Вопрос: Почему случайный выбор признаков важен?
**Ответ:**
Это делает деревья **менее скоррелированными**. Если бы мы всегда перебирали все признаки, то сильный признак выбирался бы в корне каждого дерева, и все деревья были бы похожи друг на друга. Декорреляция деревьев позволяет сильнее снизить дисперсию (разброс) ансамбля.

#### Вопрос: Что случится со смещением и разбросом, если убрать одно дерево?
**Ответ:**
*   **Смещение (Bias)**: Не изменится. Каждое дерево несмещенное (обычно глубокое), и их усреднение не меняет смещение.
*   **Разброс (Variance)**: Слегка **увеличится**. Чем больше независимых моделей мы усредняем, тем меньше дисперсия среднего ($\propto 1/T$). Убирая дерево, мы ослабляем эффект усреднения.

---

### Градиентный бустинг (Gradient Boosting)

#### Вопрос: Как работает градиентный бустинг?
**Ответ:**
Это последовательное построение ансамбля, где каждый следующий алгоритм пытается предсказать **ошибку** (антиградиент функции потерь) текущего ансамбля.
**Алгоритм**:
1.  Строим константный прогноз (например, среднее).
2.  Считаем остатки (ошибки) для каждого объекта: $r_i = y_i - \hat{y}_i$ (для MSE).
3.  Обучаем новое дерево $f_m$ предсказывать эти остатки $r_i$.
4.  Обновляем модель: $F_m(x) = F_{m-1}(x) + \eta \, f_m(x)$, где $\eta$ — learning rate.
5.  Повторяем шаги 2-4.

#### Вопрос: Почему бустинг называется градиентным?
**Ответ:**
Мы оптимизируем произвольную дифференцируемую функцию потерь $L$. Чтобы минимизировать её методом градиентного спуска в пространстве функций, мы на каждом шаге добавляем дерево, которое направлено в сторону **антиградиента** функции потерь: $- \nabla_{F} L$.
Для MSE антиградиент — это просто разность $(y_i - \hat{y}_i)$.

#### Вопрос: Какой глубины деревья используются в бустинге и почему?
**Ответ:**
Используются **неглубокие** деревья (слабые модели, глубина 3-6).
*   Глубокие деревья имеют низкое смещение, но высокий разброс (переобучаются).
*   Бустинг снижает смещение (Bias), последовательно исправляя ошибки. Если базовые модели уже будут сложными (глубокими) и переобученными, бустинг моментально переобучится. Ему нужны "тупые" модели с высоким смещением, которые он исправит.

#### Вопрос: Что случится со смещением и разбросом, если убрать один шаг (дерево) бустинга?
**Ответ:**
*   **Смещение (Bias)**: **Увеличится**. Каждое новое дерево исправляет ошибки, приближая модель к идеалу. Убрав шаг, мы недоисправим ошибку.
*   **Разброс (Variance)**: Практически не изменится (или слегка уменьшится, так как модель станет проще). Разброс в бустинге контролируется глубиной деревьев и learning rate, а не количеством (как в лесе).

#### Вопрос: Можно ли распараллелить обучение бустинга?
**Ответ:**
**Нет**, деревья строятся строго последовательно (каждое зависит от предыдущего). Однако можно распараллелить построение *одного* дерева (поиск сплитов), что реализовано в XGBoost/LightGBM. Случайный лес параллелится отлично (деревья независимы).

#### Вопрос: В каких случаях линейная регрессия лучше бустинга?
**Ответ:**
1.  Если зависимость в данных **строго линейная** (бустинг — это сумма ступенек, ему сложно аппроксимировать прямую линию, особенно наклонную).
2.  При **экстраполяции** (линейная регрессия продолжит тренд, бустинг упрется в константу).
3.  Очень мало данных или очень много шума (бустинг переобучится).
4.  Нужна максимальная интерпретируемость.

---

### Работа с данными

#### Вопрос: Как бороться с дисбалансом классов?
**Ответ:**
1.  **Class Weights**: Дать больше веса ошибкам на редком классе.
2.  **Resampling**:
    *   *Undersampling*: Выкинуть часть мажоритарного класса.
    *   *Oversampling*: Дублировать миноритарный класс или генерировать синтетику (SMOTE).
3.  **Правильные метрики**: Использовать PR-AUC или F1, а не Accuracy.
4.  **Специальные лоссы**: Focal Loss (в бустингах), который фокусируется на сложных примерах.

#### Вопрос: Что делать, если в данных много признаков?
**Ответ:**
1.  **L1-регуляризация** (Lasso): Занулит веса лишних признаков.
2.  **Отбор по важности**: Обучить случайный лес, взять топ важных признаков.
3.  **PCA (Метод главных компонент)**: Сжать признаки в новые ортогональные компоненты, сохранив дисперсию.
    *   *Минус PCA*: Теряется интерпретируемость (новые оси — это линейные комбинации старых).

#### Вопрос: Нормализация vs Стандартизация?
**Ответ:**
*   **Деревянные методы (Лес, Бустинг)**: **Не требуют** ни того, ни другого. Им важен только порядок значений.
*   **Линейные модели, KNN, Нейросети**: **Требуют**.
    *   *Стандартизация (Z-score)*: Если распределение нормальное или есть выбросы (она устойчивее MinMax).
    *   *Нормализация (MinMax)*: Если нужно загнать в строгий диапазон [0, 1] (например, для картинок).

## Практические задачи по ML: Регрессия, Классификация, Нейросети

### Задача 1. Экстраполяция алгоритмов
**Условие:** Есть обучающая выборка (train), сосредоточенная в левой части графика (малые $x$). Есть тестовая выборка (test), смещенная вправо (большие $x$). Как будут выглядеть предсказания на тесте для разных моделей?

**Ответ:**

1.  **Линейная регрессия:**
    *   **Вид на графике:** Прямая наклонная линия, уходящая вверх (или вниз, в зависимости от тренда train).
    *   **Поведение:** Модель выучивает уравнение прямой $y = wx + b$. Она **экстраполирует** зависимость. Если на train был рост, то на test она предскажет очень большие значения, продолжая этот рост.

2.  **Решающее дерево (Decision Tree):**
    *   **Вид на графике:** Горизонтальная прямая линия (константа) на уровне последнего листа.
    *   **Поведение:** Деревья **не умеют экстраполировать**. Они разбивают пространство на прямоугольники. Для любого $x$, который больше максимального $x$ из обучения, дерево выдаст значение из самого крайнего правого "листа" (обычно это среднее значение последних точек train).

3.  **K-Means (как регрессор/кластеризатор):**
    *   **Вид на графике:** Горизонтальная линия.
    *   **Поведение:** Если мы используем центроиды кластеров для предсказания (или присваиваем значение ближайшего кластера), то все далекие точки тестовой выборки будут отнесены к самому близкому (крайнему правому) кластеру из train. Предсказание будет константным — координата центра этого кластера.

---

### Задача 2 и 5. Предсказание отрицательных значений
**Условие:** В обучающей выборке все целевые значения положительные ($y > 0$). Какие модели могут предсказать отрицательное значение на тесте?

**Ответ:**

| Алгоритм | Может дать $y < 0$? | Объяснение |
| :--- | :---: | :--- |
| **Линейная регрессия** | **Да** | Прямая линия уходит в бесконечность. При определенных входных данных $x$ (например, далеко от обучающей выборки) результат уравнения $wx+b$ может стать меньше нуля. |
| **Градиентный бустинг** | **Да** | Бустинг суммирует поправки (остатки). Даже если базовое предсказание положительное, сумма отрицательных корректировок может увести итоговый прогноз в минус. |
| **Нейронная сеть** | **Да** | Если на выходе нет ограничивающей функции активации (например, стоит Linear или Tanh), сеть может выдать любое число. |
| **Полиномиальная регрессия**| **Да** | Как и линейная, это функция, которая может пересечь ось X. |
| **K-ближайших соседей (KNN)**| **Нет** | Предсказание — это среднее значение $k$ соседей. Если все соседи из train положительные, их среднее тоже будет положительным. |
| **Решающее дерево** | **Нет** | В листе хранится среднее значение попавших туда объектов. Среднее положительных чисел всегда положительно. |
| **Случайный лес** | **Нет** | Это усреднение прогнозов деревьев. Среднее положительных прогнозов всегда положительно. |

---

### Задача 3. Расчет выхода нейросети
**Условие:**
*   Входы: $x_1=1, x_2=1, x_3=1, x_4=1$. Смещение (bias) = 0.
*   Веса скрытого слоя:
    *   Нейрон 1: $w_1 = -3, w_2 = 2$.
    *   Нейрон 2: $w_3 = 4, w_4 = 1$.
*   Веса выходного слоя:
    *   От Нейрона 1 к выходу: $w_5 = -1$.
    *   От Нейрона 2 к выходу: $w_6 = 2$.
*   Нужно рассчитать $Y$ для разных функций активации и отранжировать их.

**Решение:**

1.  **Считаем суммы на входе нейронов ($S$):**
    *   $S_1 = x_1 w_1 + x_2 w_2 = 1 \cdot (-3) + 1 \cdot 2 = -1$
    *   $S_2 = x_3 w_3 + x_4 w_4 = 1 \cdot 4 + 1 \cdot 1 = 5$

2.  **Считаем выход $Y$ для разных функций $f(x)$:**
    Формула выхода: $Y = f(S_1) \cdot w_5 + f(S_2) \cdot w_6 = f(-1) \cdot (-1) + f(5) \cdot 2$.

    *   **Линейная ($f(x)=x$):**
        $Y = (-1) \cdot (-1) + (5) \cdot 2 = 1 + 10 = \mathbf{11}$.

    *   **ReLU ($f(x) = \max(0, x)$):**
        $f(-1) = 0, \quad f(5) = 5$.
        $Y = 0 \cdot (-1) + 5 \cdot 2 = 0 + 10 = \mathbf{10}$.

    *   **Сигмоида ($f(x) = \frac{1}{1+e^{-x}}$):**
        $f(-1) \approx 0.27, \quad f(5) \approx 0.99$.
        $Y \approx 0.27 \cdot (-1) + 0.99 \cdot 2 = -0.27 + 1.98 = \mathbf{1.71}$.

    *   **Tanh ($f(x) = \tanh(x)$):**
        $f(-1) \approx -0.76, \quad f(5) \approx 1.0$.
        $Y \approx (-0.76) \cdot (-1) + 1.0 \cdot 2 = 0.76 + 2 = \mathbf{2.76}$.

3.  **Ранжирование по возрастанию Y:**
    1.  Сигмоида (1.71) — №2
    2.  Tanh (2.76) — №4
    3.  ReLU (10) — №3
    4.  Линейная (11) — №1

**Ответ:** 2431

---

### Задача 4. Анализ кривых обучения (Learning Curves)
**Условие:** На графике точность на валидации (Validation Accuracy) **выше**, чем на трейне (Training Accuracy), а потери (Loss) на валидации **ниже**, чем на трейне. Это необычно.

**Возможные причины:**

1.  **Агрессивная аугментация (Augmentation):**
    *   При обучении к картинкам применяются сложные искажения (повороты, шумы, обрезка), поэтому модели трудно учиться.
    *   Валидация проводится на "чистых", оригинальных картинках, которые классифицировать легче.
2.  **Dropout / Регуляризация:**
    *   Во время обучения (Train) часть нейронов выключена (Dropout), что снижает точность.
    *   Во время валидации (Validation) все нейроны работают, и модель показывает свою полную мощность.
3.  **Маленькая выборка / Утечка данных (Data Leak):**
    *   Валидационная выборка может случайно оказаться слишком простой или содержать дубликаты из трейна.
4.  **Разница в расчёте метрик:**
    *   Loss на трейне часто считается как среднее *в течение* эпохи (пока веса еще обновляются).
    *   Loss на валидации считается *в конце* эпохи (когда веса уже обучены и оптимальны).

---

### Задача 6. Расчет метрик (Imbalanced Data)
**Условие:**
*   Тестовые данные: 99% класс $1$ (Positive), 1% класс $-1$ (Negative).
*   Предсказание модели: Случайное (50% класс $1$, 50% класс $-1$).
*   Допустим, выборка 200 объектов: 198 (Pos), 2 (Neg).

**Расчет Confusion Matrix:**
Поскольку предсказание случайно и не зависит от реальности (вероятность 0.5):
*   **TP (True Positive):** Половина от реальных Positive = $198 \times 0.5 = 99$.
*   **FN (False Negative):** Вторая половина реальных Positive = $99$.
*   **FP (False Positive):** Половина от реальных Negative = $2 \times 0.5 = 1$.
*   **TN (True Negative):** Вторая половина реальных Negative = $1$.

**Метрики:**
1.  **Accuracy** (Доля верных):
    $\frac{TP + TN}{Total} = \frac{99 + 1}{200} = \frac{100}{200} = \mathbf{0.5}$.
2.  **Precision** (Точность):
    $\frac{TP}{TP + FP} = \frac{99}{99 + 1} = \frac{99}{100} = \mathbf{0.99}$.
3.  **Recall** (Полнота):
    $\frac{TP}{TP + FN} = \frac{99}{99 + 99} = \frac{99}{198} = \mathbf{0.5}$.

**Вывод:** Высокий Precision здесь обманчив и вызван дисбалансом классов (очень мало FP, потому что негативных примеров в принципе почти нет).

---

### Задача 7. Дерево vs Случайный Лес
**Вопрос:** В какой ситуации одно Решающее Дерево сработает лучше, чем Случайный Лес?

**Ответ:**
Дерево может быть лучше в случае, если:
1.  **В данных есть очень мало важных признаков (сильный сигнал) среди кучи шума.**
    *   Обычное дерево сразу найдет эти важные признаки и построит на них сплиты.
    *   Случайный лес использует *feature bagging* (выбирает случайное подмножество признаков для каждого дерева). Из-за этого во многих деревьях важные признаки могут просто не попасть в выборку, и эти деревья будут строиться на "шуме", ухудшая общий результат ансамбля.
2.  **Важна интерпретируемость.** Одно дерево легко визуализировать и объяснить, лес — это "черный ящик".
3.  **Ограничения по времени/ресурсам.** Одно дерево строится и работает быстрее.


## Кластеризация

### 1. Введение в unsupervised learning
Кластеризация — это задача разбиения множества объектов $X = {x_1, ..., x_n}$ на $K$ групп (кластеров) $C = {c_1, ..., c_K}$ таким образом, чтобы объекты внутри одной группы были более похожи друг на друга, чем на объекты из других групп.

В отличие от классификации, у нас **нет правильных ответов** ($y_{true}$). Мы ищем скрытую структуру данных.

**Основные вызовы:**

1. **Определение "похожести":** Евклидово расстояние работает плохо в высокой размерности.
    
2. **Форма кластеров:** Не все кластеры — это шары. Бывают кольца, спирали, вытянутые "сигары".
    
3. **Масштабируемость:** Алгоритмы $O(N^2)$ (иерархические) умирают на $N > 50k$.
    

---

### 2. Классические методы

#### 2.1. Геометрические (Centroid-based)

##### K-Means (Метод К-средних)

Самый популярный алгоритм. Разбивает данные на $K$ ячеек Вороного.

**Алгоритм (Lloyd's Algorithm):**

1. **Init:** Выбрать $K$ случайных центроидов $\mu_1, ..., \mu_K$.
    
2. **Assignment:** Для каждой точки $x_i$ найти ближайший центроид:  
    zi=arg⁡min⁡j∣∣xi−μj∣∣2zi=argminj∣∣xi−μj∣∣2
    
3. **Update:** Пересчитать центроиды как среднее арифметическое точек кластера:  
    μj=1∣Cj∣∑x∈Cjxμj=∣Cj∣1∑x∈Cjx
    
4. Повторять 2-3 до сходимости.
    

**K-Means++ (Умная инициализация):**  
Проблема обычного рандома — если два центроида упадут рядом, алгоритм может сойтись в плохой локальный минимум.

- _Идея:_ Выбираем первый центроид случайно. Следующие выбираем с вероятностью, пропорциональной квадрату расстояния до _ближайшего_ уже выбранного центроида ($P(x) \sim D(x)^2$). Это "расталкивает" начальные центры.
    

**Плюсы/Минусы:**  
✅ $O(N)$ — очень быстро.  
❌ Нужен параметр $K$.  
❌ Находит только выпуклые (сферические) кластеры.  
❌ Чувствителен к выбросам (среднее сильно смещается).

##### K-Medians / K-Medoids

Модификации для устойчивости (Robustness).

- **K-Medians:** Вместо среднего берем покомпонентную медиану. Минимизирует L1 норму (Манхэттенское расстояние).
    
- **K-Medoids (PAM):** Центроидом всегда является **реальная точка** из датасета (медоид), а не усредненная фантомная точка. Полезно, если "среднего" не существует (например, среднее двух графов или ДНК).
    

---

#### 2.2. Плотностные (Density-based)

Позволяют находить кластеры произвольной формы и выделять шум (Noise).

##### DBSCAN (Density-Based Spatial Clustering of Applications with Noise)

Определяет кластеры как области высокой плотности, разделенные областями низкой плотности.

**Параметры:**

- `eps` ($\epsilon$): Радиус окрестности.
    
- `min_samples`: Минимальное кол-во точек внутри $\epsilon$, чтобы считать точку "ядром".
    

**Типы точек:**

1. **Core (Ядро):** Имеет $\ge$ min_samples соседей.
    
2. **Border (Граничная):** Соседей мало, но находится в радиусе $\epsilon$ от Core точки.
    
3. **Noise (Шум):** Ни то, ни другое.
    

**Алгоритм:**  
Берем точку. Если она Core, начинаем "заливку" (распространяем кластер на всех соседей). Если Border — присоединяем к текущему. Если Noise — пропускаем.

**Плюсы/Минусы:**  
✅ Находит любые формы (кольца, дуги).  
✅ Сам определяет кол-во кластеров.  
❌ **Критичен к $\epsilon$:** Если в данных есть плотный кластер и разреженный кластер, невозможно подобрать один $\epsilon$ для обоих. Плотный склеится, или разреженный рассыпется на шум.

##### HDBSCAN (Hierarchical DBSCAN) [SOTA для таблиц]

Решает проблему разной плотности.

**Как работает (Steps):**[hdbscan.readthedocs+1](https://hdbscan.readthedocs.io/en/latest/how_hdbscan_works.html)​

1. **Transform Space:** Искажает пространство так, чтобы разреженные точки отдалились еще дальше (Mutual Reachability Distance).  
    dmreach(a,b)=max⁡{corek(a),corek(b),d(a,b)}dmreach(a,b)=max{corek(a),corek(b),d(a,b)}
    
2. **Build MST:** Строит минимальное остовное дерево графа.
    
3. **Cluster Hierarchy:** Превращает MST в дендрограмму, сортируя ребра по весу.
    
4. **Condense Tree:** Сжимает дерево. Если при расщеплении кластера отваливается мало точек (< min_cluster_size), мы считаем это шумом, а не новым кластером.
    
5. **Extract Clusters:** Выбирает наиболее "стабильные" кластеры. Стабильность — это объем (площадь) кластера на графике "$\lambda$ (плотность) vs Size".  
    Stability=∑p∈cluster(λp−λbirth)Stability=∑p∈cluster(λp−λbirth)
    

**Плюсы:**  
✅ Не нужен $\epsilon$.  
✅ Soft Clustering (вероятности для точек).  
✅ Работает с переменной плотностью.

---

#### 2.3. Иерархические (Hierarchical)

Строят дерево вложенности кластеров.

- **Agglomerative (Снизу-вверх):** Сначала каждая точка — свой кластер. На каждом шаге объединяем два самых близких кластера.
    
- **Linkage Criteria (Как мерить расстояние между кластерами A и B):**
    
    - _Single:_ $\min d(a, b)$. "Цепная реакция", вытягивает кластеры в "колбаски".
        
    - _Complete:_ $\max d(a, b)$. Стремится к компактным сферам.
        
    - _Ward:_ Минимизация прироста дисперсии при объединении. Самый популярный метод.
        

---

### 3. Метрики

Как объяснить бизнесу, что кластеризация "удалась"?

#### 3.1. Internal Metrics (Без разметки)

Используются для подбора гиперпараметров ($K$, $\epsilon$).

1. **Silhouette Score ($S \in [-1, 1]$):**
    Для каждой точки считаем $a$ (среднее расстояние до своих) и $b$ (среднее до ближайшего чужого).  
    $$S=b−\ a \ max⁡(a,b)$$
    
    - **Интерпретация:**
        
        - $0.71 - 1.0$: Отличная структура.
            
        - $0.51 - 0.7$: Разумная структура.
            
        - $0.26 - 0.5$: Слабая структура, кластеры перекрываются.
            
        - $< 0.25$ или **Отрицательные значения:** Точки перепутаны, кластеры не имеют смысла. Скорее всего, данные случайны или $K$ выбрано неверно.
            
2. **Davies-Bouldin Index (DBI):**
    Оценивает отношение "разброса внутри кластера" к "расстоянию между кластерами".
    
    - **Интерпретация:** Чем **меньше**, тем лучше (от 0 до $\infty$). Хороший кластер — это компактное облако, далекое от других. Значения зависят от датасета, сравнивать можно только разные модели на одних данных.
        
3. **Calinski-Harabasz Index (Variance Ratio):**
    Отношение межкластерной дисперсии к внутрикластерной.
    
    - **Интерпретация:** Чем **выше**, тем лучше. Предпочитает выпуклые (шарообразные) кластеры. Плохо работает для сложных форм (как DBSCAN).
        

#### 3.2. External Metrics (С разметкой)

Используются, если у нас есть "золотой стандарт" (Ground Truth), но мы хотим проверить алгоритм.

1. **ARI (Adjusted Rand Index):**[scikit-learn+1](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.adjusted_rand_score.html)​
    
    - **Интерпретация:**
        
        - $1.0$: Идеальное совпадение.
            
        - $0.0$: Результат не лучше случайного (Random).
            
        - Negative ($<0$): Результат **хуже** случайного (систематическая ошибка).
            

#### 3.3. Бизнес-интерпретация (Profiling)[aidancooper+1](https://www.aidancooper.co.uk/supervised-clustering-shap-values/)​

Бизнесу не нужны метрики, им нужны инсайты ("Кто эти люди?").

1. **Centroid Analysis:**  
    Строим Radar Chart (Spider Plot) для центроидов.
    
    - _Пример:_ "Кластер 1: Доход высокий, Возраст 40+, Траты на авто". $\to$ "Богатые автомобилисты".
        
2. **Decision Tree Explainer:**  
    Обучаем `DecisionTreeClassifier` предсказывать `cluster_id` по фичам.
    
    - Визуализируем дерево: "Если Income > 100k и Age > 40 $\to$ Cluster 1". Это дает четкие правила для маркетинга.
        
3. **SHAP Values (Supervised Clustering):**  
    Используем SHAP для объяснения модели классификатора кластеров. Показывает, какие именно фичи внесли вклад в то, что клиент попал в Кластер 3.
    

---

### 4. SOTA Подходы

Классические методы работают с "готовыми" фичами. Deep Clustering учит фичи (Embeddings) специально под кластеризацию.

#### 4.1. General & CV (Картинки, Общие данные)

##### Deep Embedded Clustering (DEC)​

Архитектура, изменившая подход к задаче.  
**Суть:** Итеративное улучшение кластеров через самообучение (Self-training).

**Процесс:**

1. **Pre-training:** Обучаем Stacked Autoencoder (SAE) восстанавливать вход. Получаем латентное пространство $Z$.
    
2. **Initialization:** Запускаем K-Means на $Z$, получаем начальные центроиды $\mu_j$.
    
3. **Clustering Loop:**
    
    - **Soft Assignment ($q_{ij}$):** Считаем вероятность принадлежности точки $z_i$ к кластеру $j$ (через t-распределение Стьюдента, как в t-SNE):  
        qij=(1+∣∣zi−μj∣∣2)−1∑k(1+∣∣zi−μk∣∣2)−1qij=∑k(1+∣∣zi−μk∣∣2)−1(1+∣∣zi−μj∣∣2)−1
        
    - **Target Distribution ($p_{ij}$):** Искусственно заостряем распределение $q$. Возводим в квадрат и нормализуем. Это заставляет модель быть "увереннее".  
        pij∝qij2∑iqijpij∝∑iqijqij2
        
    - **Loss:** KL-дивергенция $KL(P || Q)$. Мы заставляем сеть предсказывать наши же заостренные метки.
        

##### Contrastive Clustering (SwAV, SCAN)​[github](https://github.com/Wolfda95/SSL-MedicalImagining-CL-MAE)​

Подход из Self-Supervised Learning (SSL).  
**SwAV (Swapping Assignments between Views):**

- Вместо сравнения векторов картинок (как в SimCLR), сравниваем их **назначения кластерам**.
    
- Генерируем два кропа (view) одной картинки: $x_1, x_2$.
    
- Считаем их коды кластеров $q_1, q_2$ (через Sinkhorn-Knopp для балансировки, чтобы все кластеры были равного размера).
    
- **Задача:** Предсказать $q_2$ по фичам $z_1$, и $q_1$ по фичам $z_2$.
    
- _Результат:_ Кластеризация происходит "бесплатно" в процессе обучения фич-экстрактора.
    

#### 4.2. Tabular Data (Таблицы)

##### TabNet​

Нейросеть, имитирующая деревья решений.

- Использует **Sparsemax** маски для выбора фич на каждом шаге (Feature Selection).
    
- Для кластеризации используется **Pre-training task**: маскируем часть колонок в таблице и просим модель восстановить их (Masked Feature Prediction). Эмбеддинги с энкодера TabNet затем кластеризуются K-Means/HDBSCAN.
    

##### TabPFN (Prior-Data Fitted Network)[arxiv+1](https://arxiv.org/html/2502.02527v1)​

Революционный подход (2023-2025). Это **Transformer**, обученный _один раз_ на миллионах синтетических таблиц.

- **In-context learning:** Вы подаете ему свою таблицу как промпт.
    
- Он не учится (no Gradient Descent). Он просто делает Forward Pass и выдает предсказания.
    
- Может использоваться для классификации, но внутренние аттеншны дают отличные эмбеддинги для кластеризации малых таблиц (< 10k строк).
    

#### 4.3. Graph Data (Графы)

##### MinCutPool[mlgworkshop+1](https://www.mlgworkshop.org/2020/papers/MLG2020_paper_42.pdf)​

Дифференцируемая кластеризация графов.

- Обычно кластеризация графов — это дискретная задача (Min-Cut).
    
- Здесь GNN выдает матрицу принадлежности $S$ (assignment matrix).
    
- **Loss:** Минимизирует количество связей между кластерами (Cut loss) + максимизирует ортогональность кластеров.
    
- Позволяет делать **Hierarchical Pooling**: граф сворачивается в супер-узлы, потом еще раз, пока не останется один узел.
    

##### DMoN (Deep Modularity Networks)[jmlr](https://jmlr.org/papers/volume24/20-998/20-998.pdf)​

Улучшение MinCutPool.

- Минимизация MinCut часто приводит к вырождению (один огромный кластер и много пустых).
    
- **DMoN** оптимизирует **Модулярность (Modularity)** — метрику, сравнивающую плотность связей внутри кластера с ожидаемой плотностью в случайном графе (Null Model).
    
- Это спектральный метод, встроенный в нейросеть.
    

---

### 5. Препроцессинг и сжатие векторов

Кластеризация в сыром пространстве высокой размерности (>50-100 фич) обречена на провал ("Проклятие размерности"). Расстояния теряют смысл.

#### PCA vs t-SNE vs UMAP​

|Метод|Тип|Сохраняет структуру|Скорость|Для кластеризации?|
|---|---|---|---|---|
|**PCA**|Линейный|Глобальную (дисперсию)|🚀 Очень быстро|✅ Да (как препроцессинг)|
|**t-SNE**|Нелинейный|**Только локальную**(соседей)|🐢 Медленно ($O(N^2)$)|❌ **НЕТ!** Искажает плотность и расстояния между кластерами. Только для визуализации.|
|**UMAP**|Нелинейный (Топологический)|Локальную + Глобальную|🚀 Быстро|✅ **ДА.** Лучший выбор.|

**Почему UMAP лучше для кластеризации?**  
UMAP (Uniform Manifold Approximation and Projection) строит граф ближайших соседей и оптимизирует его low-dim проекцию. В отличие от t-SNE, он сохраняет относительные расстояния между _далекими_ кластерами и плотность точек. HDBSCAN поверх UMAP — золотой стандарт для сложных данных.

---

### 6. Продакшн и масштабируемость

#### 6.1. Библиотеки для Big Data

1. **Faiss (Facebook):**
    
    - Реализует K-Means на GPU.
        
    - Может кластеризовать 1 млрд векторов за минуты.
        
    - Использует инвертированные индексы (IVF) для ускорения.
        
2. **Mini-Batch K-Means (Sklearn):**
    
    - Обновляет центроиды на небольших случайных батчах данных.
        
    - Качество чуть хуже, но скорость на порядки выше. Потребление памяти константное.
        
3. **Cuml (RAPIDS):**
    
    - DBSCAN, UMAP, HDBSCAN, K-Means полностью на GPU.
        
    - API совпадает с sklearn.